{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto I \n",
    "* Monica Alfaro Parrales\n",
    "* Adrián Ramírez Mattey\n",
    "* Gilberth Rodríguez Mejías "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del dataset \"Pima Indians Diabetes Database\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from IPython.display import display\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('diabetes.csv')\n",
    "print(\"data head\")\n",
    "display(data.head())\n",
    "print(\"data describe\")\n",
    "display(data.describe())\n",
    "display(data)\n",
    "\n",
    "X = data[[\n",
    "    'Pregnancies',\n",
    "    'Glucose',\n",
    "    'BloodPressure',\n",
    "    'SkinThickness',\n",
    "    'Insulin',\n",
    "    'BMI',\n",
    "    'DiabetesPedigreeFunction',\n",
    "    'Age'\n",
    "]].values\n",
    "\n",
    "y = data['Outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminación de outliers y división del dataset\n",
    "Se procede a hacer uso de IQR, el rango intercuartil (IQR) es la diferencia entre el percentil 75 y el 25 de los datos. Es una medida de dispersión similar a la desviación estándar o la varianza, pero es mucho más robusta frente a valores atípicos. Posteriormente, se hace un shuffle de la data para asegurar una mayor distribución y se divide el dataset en un 80% training y 20% testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el IQR\n",
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identifica los outliers\n",
    "outliers = ((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR)))\n",
    "\n",
    "# Encuentra las filas que tienen al menos un outlier\n",
    "outliers_indices = outliers.any(axis=1)\n",
    "\n",
    "# Muestra las filas con outliers\n",
    "print(\"Filas con outliers:\")\n",
    "print(data[outliers_indices])\n",
    "\n",
    "# Elimina los outliers\n",
    "data_sin_outliers = data[~outliers_indices]\n",
    "\n",
    "# Muestra el conjunto de datos sin outliers\n",
    "print(\"Data sin outliers:\")\n",
    "print(data_sin_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Antes de dividir los datos, barajamos el dataset de forma aleatoria para mayor diversidad de datos\n",
    "dataset_shuffled = shuffle(data_sin_outliers, random_state=50)  # random_state para reproducibilidad\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "p_train = 0.8  # Porcentaje de training set\n",
    "train_index = int(len(dataset_shuffled) * p_train)\n",
    "\n",
    "dataFrameTraining = dataset_shuffled[:train_index]\n",
    "\n",
    "dataFrameTesting = dataset_shuffled[train_index:]\n",
    "\n",
    "print(\"Ejemplos usados para entrenar: \", len(dataFrameTraining))\n",
    "print(\"Ejemplos usados para test: \", len(dataFrameTesting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGroup = data.groupby('Outcome')\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.hist(dataGroup['Pregnancies'].get_group(0), bins=30, alpha=0.5, label='0')\n",
    "plt.hist(dataGroup['Pregnancies'].get_group(1), bins=30, alpha=0.5, label='1')\n",
    "plt.title('Histograma de Diabetes - Embarazos')\n",
    "plt.xlabel('Embarazos')\n",
    "plt.ylabel('Personas')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.hist(dataGroup['Glucose'].get_group(0), bins=30, alpha=0.5, label='0')\n",
    "plt.hist(dataGroup['Glucose'].get_group(1), bins=30, alpha=0.5, label='1')\n",
    "plt.title('Histograma de Diabetes - Glucosa')\n",
    "plt.xlabel('Glucosa')\n",
    "plt.ylabel('Personas')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('diabetes.csv')\n",
    "print(\"data head\")\n",
    "display(data.head())\n",
    "print(\"data describe\")\n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "Las redes neuronales son modelos creados al ordenar operaciones matemáticas siguiendo una determinada estructura. La forma más común de representar la estructura de una red neuronal es mediante el uso de capas (layers), formadas a su vez por neuronas (unidades, units o neurons). Cada neurona, realiza una operación sencilla y está conectada a las neuronas de la capa anterior y de la capa siguiente mediante pesos, cuya función es regular la información que se propaga de una neurona a otra.\n",
    "\n",
    "Parámetros:\n",
    "* hidden_layer_sizes: número y tamaño de las capas ocultas. Por ejemplo, (100) para una única capa oculta con 100 neuronas, y (16, 16) para dos capas ocultas de 16 neuronas de cada una. El valor por defecto es (100,).\n",
    "* learning_rate: estrategia para modificar el learning rate durante el entrenamiento. Solo se utiliza cuando solver='sgd'. Puede ser:\n",
    "    * 'constant': se utiliza el valor especificado en el argumento learning_rate_init durante todo el proceso de entrenamiento.\n",
    "    *'invscaling': se reduce progresivamente el learning rate en cada iteración t utilizando una función exponecial effective_learning_rate = learning_rate_init / pow(t, power_t).\n",
    "    * adaptive: mantiene constante el valor especificado en el argumento learning_rate_init siempre y cuando el modelo siga mejorando (reducción de la función de coste). Si entre dos épocas consecutivas el modelo no mejora un mínimo definido en el argumento tol, el learning rate se divide por 5.\n",
    "* learning_rate_init: valor inicial de learning rate. Solo se utiliza cuando el solver es 'sgd' o 'adam'. Por defecto el valor es 0.001.\n",
    "* solver: el algoritmo de optimización utilizado para aprender los pesos y bias de la red. Puede ser: {'lbfgs', 'sgd', 'dam'}. Por defecto se utiliza 'adam', que es el que mejores resultados suele dar para conjuntos de datos con miles de observaciones. Para sets de datos pequeños, 'lbfgs' converge más rápido y puede conseguir mejores resultados.\n",
    "* max_iter: número máximo de iteraciones de entrenamiento. Para los solvers estocásticos ('sgd' y 'adam') este valor se corresponde con el número de épocas (cuantas veces participa en el entrenamiento cada observación). Se emplean por defecto 200.\n",
    "* shuffle: si se mezclan aleatoriamente las observaciones en cada iteración. Por defecto es True.\n",
    "* random_state: semilla utilizada para todos los pasos del entrenaiento que requieren de valores aleatorios (inicialización depesos, splits, bias).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_1 = MLPClassifier(\n",
    "                hidden_layer_sizes=(50, 50, 50),\n",
    "                learning_rate_init=0.01,\n",
    "                solver = 'lbfgs',\n",
    "                max_iter = 5000,\n",
    "                random_state = 123\n",
    "            )\n",
    "X_train = dataFrameTraining[[\n",
    "    'Pregnancies',\n",
    "    'Glucose',\n",
    "    'BloodPressure',\n",
    "    'SkinThickness',\n",
    "    'Insulin',\n",
    "    'BMI',\n",
    "    'DiabetesPedigreeFunction',\n",
    "    'Age'\n",
    "]].values\n",
    "\n",
    "y_train = dataFrameTraining['Outcome']\n",
    "\n",
    "X_test = dataFrameTesting[[\n",
    "    'Pregnancies',\n",
    "    'Glucose',\n",
    "    'BloodPressure',\n",
    "    'SkinThickness',\n",
    "    'Insulin',\n",
    "    'BMI',\n",
    "    'DiabetesPedigreeFunction',\n",
    "    'Age'\n",
    "]].values\n",
    "\n",
    "y_test = dataFrameTesting['Outcome']\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "modelo_1.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo con los datos de prueba\n",
    "accuracy = modelo_1.score(X_test, y_test)\n",
    "print(f'Exactitud del modelo en el conjunto de prueba: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga del dataset \"The Spotify Hit Predictor Dataset (1960-2019)\" específico del 2010 al 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.hist(dataGroup['Insulin'].get_group(0), bins=30, alpha=0.5, label='0')\n",
    "plt.hist(dataGroup['Insulin'].get_group(1), bins=30, alpha=0.5, label='1')\n",
    "plt.title('Histograma de Diabetes - Insulina')\n",
    "plt.xlabel('Insulina')\n",
    "plt.ylabel('Personas')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.hist(dataGroup['BMI'].get_group(0), bins=30, alpha=0.5, label='0')\n",
    "plt.hist(dataGroup['BMI'].get_group(1), bins=30, alpha=0.5, label='1')\n",
    "plt.title('Histograma de Diabetes - BMI')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Personas')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.hist(dataGroup['DiabetesPedigreeFunction'].get_group(0), bins=30, alpha=0.5, label='0')\n",
    "plt.hist(dataGroup['DiabetesPedigreeFunction'].get_group(1), bins=30, alpha=0.5, label='1')\n",
    "plt.title('Histograma de Diabetes - DiabetesPedigreeFunction')\n",
    "plt.xlabel('DiabetesPedigreeFunction')\n",
    "plt.ylabel('Personas')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.hist(dataGroup['Age'].get_group(0), bins=30, alpha=0.5, label='0')\n",
    "plt.hist(dataGroup['Age'].get_group(1), bins=30, alpha=0.5, label='1')\n",
    "plt.title('Histograma de Diabetes - Edad')\n",
    "plt.xlabel('Edad')\n",
    "plt.ylabel('Personas')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga del dataset \"The Spotify Hit Predictor Dataset (1960-2019)\" específico del 2010 al 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset-of-10s.csv')\n",
    "print(\"data head\")\n",
    "display(data.head())\n",
    "print(\"data info\")\n",
    "display(data.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
